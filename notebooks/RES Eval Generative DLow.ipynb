{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spread-dayton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Code/experiments-motion\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abroad-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affected-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('./Motion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "outdoor-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from motion import Quaternion\n",
    "from h36m.skeleton import H36MSkeleton\n",
    "from h36m.dataset.h36m_torch_dataset import H36MTorchDataset\n",
    "from h36m.dataset.h36m_dataset import H36MDataset\n",
    "from h36m.dataset.h36m_test_dataset import H36MTestDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contained-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import MeanAngleL2Error, MeanPerJointPositionError, NegativeLogLikelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-function",
   "metadata": {},
   "source": [
    "# Load H3.6M Skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surface-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load skeleton configuration\n",
    "with open('./config/h36m_skeleton.yaml', 'r') as stream:\n",
    "    skeleton = H36MSkeleton(**yaml.safe_load(stream))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-treasure",
   "metadata": {},
   "source": [
    "## Define Eval Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "early-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_l2_metric = MeanAngleL2Error(ignore_root=True) # We ignore the root rotation in the world for the origin joint\n",
    "mpjpe_metric = MeanPerJointPositionError()\n",
    "nll_metric = NegativeLogLikelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adjacent-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [0.08, 0.16, 0.32, 0.4, 0.56, 0.72, 0.88, 1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-barrel",
   "metadata": {},
   "source": [
    "# Generative Evaluation DLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tired-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/processed/h3.6m.npz'\n",
    "h36m_dataset = H36MDataset(DATA_PATH, dataset_fps=50, dataset_downsample_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qualified-straight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Code/experiments-motion/compare/DLow\n"
     ]
    }
   ],
   "source": [
    "cd ./compare/DLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "external-valentine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "metallic-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.motion_pred import *\n",
    "from motion_pred.utils.config import Config\n",
    "from motion_pred.eval import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0250c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "def compute_kde_nll(y, y_pred):\n",
    "    bs, sp, ts, ns, d = y_pred.shape\n",
    "    kde_ll = torch.zeros((bs, ts, ns))\n",
    "\n",
    "    for b in range(bs):\n",
    "        for t in range(ts):\n",
    "            for n in range(ns):\n",
    "                try:\n",
    "                    kde = gaussian_kde(y_pred[b, :, t, n].T)\n",
    "                    pdf = kde.logpdf(y[b, t, n].T)\n",
    "                    kde_ll[b, t, n] = torch.tensor(pdf)\n",
    "                except np.linalg.LinAlgError:\n",
    "                    print(b, t, n)\n",
    "                    print('nan')\n",
    "                    pass\n",
    "\n",
    "    return -kde_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "controlling-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skeleton_set(skeleton, s):\n",
    "    jl = []\n",
    "    for i, p in enumerate(skeleton._parents):\n",
    "        if p > -1:\n",
    "            jl.append((s[i] - s[p]) * 1000.)\n",
    "    l = torch.tensor(np.linalg.norm(np.array(jl), axis=-1))\n",
    "    skeleton._offsets[skeleton._offsets.abs() > 0.] = l[l.abs() > 0.] * torch.sign(skeleton._offsets[skeleton._offsets.abs() > 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "greenhouse-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(data, algo, sample_num, num_seeds=1, concat_hist=True):\n",
    "    traj_np = data[..., 1:, :].reshape(data.shape[0], data.shape[1], -1)\n",
    "    traj = tensor(traj_np, device=device, dtype=dtype).permute(1, 0, 2).contiguous()\n",
    "    X = traj[:t_his]\n",
    "\n",
    "    if algo == 'dlow':\n",
    "        X = X.repeat((1, num_seeds, 1))\n",
    "        Z_g = models[algo].sample(X)\n",
    "        X = X.repeat_interleave(sample_num, dim=1)\n",
    "        Y = models['vae'].decode(X, Z_g)\n",
    "    elif algo == 'vae':\n",
    "        X = X.repeat((1, sample_num * num_seeds, 1))\n",
    "        Y = models[algo].sample_prior(X)\n",
    "\n",
    "    if concat_hist:\n",
    "        Y = torch.cat((X, Y), dim=0)\n",
    "    Y = Y.permute(1, 0, 2).contiguous().cpu().numpy()\n",
    "    if Y.shape[0] > 1:\n",
    "        Y = Y.reshape(-1, num_seeds*sample_num, Y.shape[-2], Y.shape[-1])\n",
    "    else:\n",
    "        Y = Y[None, ...]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "metric-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['dlow', 'vae']\n",
    "cfg = 'h36m_nsamp50'\n",
    "traj_dim = 48\n",
    "num_seeds = 1\n",
    "device = 'cpu'\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "earlier-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suffering-wheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_his = cfg.t_his\n",
    "t_pred = cfg.t_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "outer-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dlow model from checkpoint: results/h36m_nsamp50/models/dlow_0500.p\n",
      "loading vae model from checkpoint: results/h36m_nsamp50/models/vae_0500.p\n"
     ]
    }
   ],
   "source": [
    "\"\"\"models\"\"\"\n",
    "model_generator = {\n",
    "    'vae': get_vae_model,\n",
    "    'dlow': get_dlow_model,\n",
    "}\n",
    "models = {}\n",
    "for algo in algos:\n",
    "    models[algo] = model_generator[algo](cfg, traj_dim)\n",
    "    model_path = getattr(cfg, f\"{algo}_model_path\") % getattr(cfg, 'num_%s_epoch' % algo)\n",
    "    print(f'loading {algo} model from checkpoint: {model_path}')\n",
    "    model_cp = pickle.load(open(model_path, \"rb\"))\n",
    "    models[algo].load_state_dict(model_cp['model_dict'])\n",
    "    models[algo].to(device)\n",
    "    models[algo].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "animated-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_joints = {4, 5, 9, 10, 11, 16, 20, 21, 22, 23, 24, 28, 29, 30, 31}\n",
    "kept_joints = np.array([x for x in range(32) if x not in removed_joints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "taken-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  6,  7,  8, 12, 13, 14, 15, 17, 18, 19, 25, 26, 27])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pacific-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval_9 = H36MTorchDataset(h36m_dataset,\n",
    "                                subjects=['S9'],\n",
    "                                history_length=25,\n",
    "                                prediction_horizon=100,\n",
    "                                step=25)\n",
    "data_loader_eval = DataLoader(dataset_eval_9, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "strange-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('./data/data_3d_h36m.npz', allow_pickle=True)\n",
    "pos = d['positions_3d'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "spectacular-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_set(skeleton, pos['S9']['Phoning'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46ecb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adjustable-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]<ipython-input-16-10b9758506bc>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  traj = tensor(traj_np, device=device, dtype=dtype).permute(1, 0, 2).contiguous()\n",
      "100%|██████████| 24/24 [00:39<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pos_pred_l = []\n",
    "y_pos_l = []\n",
    "cfg.nk = 50\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(data_loader_eval):\n",
    "        x_pos = skeleton(x.view(-1, 32, 4), ignore_root=False).view(-1, x.shape[1], 32, 3) / 1000.\n",
    "        y_pos = skeleton(y.view(-1, 32, 4), ignore_root=False).view(-1, y.shape[1], 32, 3) / 1000.\n",
    "        \n",
    "        # Remove static nodes\n",
    "        data = torch.cat([x_pos, y_pos], dim=1)[..., kept_joints, :].clone()\n",
    "        \n",
    "        # Account for different coordinate system during training\n",
    "        data = data[..., [0, 2, 1]] * torch.tensor([[[1., -1., 1.]]])\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(20):\n",
    "            y_pred_i = get_prediction(data, 'dlow', sample_num=cfg.nk, num_seeds=num_seeds, concat_hist=False)\n",
    "            y_pred_i = torch.tensor(y_pred_i).view(y_pred_i.shape[:-1] + (-1, 3))\n",
    "            y_pred.append(y_pred_i)\n",
    "        y_pred = torch.cat(y_pred, dim=1)\n",
    "        \n",
    "        # Add static positions\n",
    "        y_final = y_pred\n",
    "        y_pos = y_pos[..., kept_joints[1:], :] # Origin is filtered in get_prediction\n",
    "        \n",
    "        nll_list.append(compute_kde_nll(data[:, 25:, 1:], y_final))\n",
    "        \n",
    "        y_pos_pred_l.append(y_final)\n",
    "        y_pos_l.append(data[:, 25:, 1:])\n",
    "    \n",
    "y_pos_pred_9 = torch.cat(y_pos_pred_l, dim=0)\n",
    "y_pos_9 = torch.cat(y_pos_l, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "earlier-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_eval_11 = H36MTorchDataset(h36m_dataset,\n",
    "                                subjects=['S11'],\n",
    "                                history_length=25,\n",
    "                                prediction_horizon=100,\n",
    "                                skip_11_d=True,\n",
    "                                step=25)\n",
    "data_loader_eval = DataLoader(dataset_eval_11, shuffle=False, batch_size=128)\n",
    "skeleton_set(skeleton, pos['S11']['Phoning 2'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "protective-glass",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]<ipython-input-16-10b9758506bc>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  traj = tensor(traj_np, device=device, dtype=dtype).permute(1, 0, 2).contiguous()\n",
      "100%|██████████| 17/17 [00:27<00:00,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "y_pos_pred_l = []\n",
    "y_pos_l = []\n",
    "cfg.nk = 50\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(data_loader_eval):\n",
    "        x_pos = skeleton(x.view(-1, 32, 4), ignore_root=False).view(-1, x.shape[1], 32, 3) / 1000.\n",
    "        y_pos = skeleton(y.view(-1, 32, 4), ignore_root=False).view(-1, y.shape[1], 32, 3) / 1000.\n",
    "        \n",
    "        # Remove static nodes\n",
    "        data = torch.cat([x_pos, y_pos], dim=1)[..., kept_joints, :].clone()\n",
    "        \n",
    "        data = data[..., [0, 2, 1]] * torch.tensor([[[1., -1., 1.]]])# + torch.tensor([[[0., 0., 1.]]])\n",
    "        \n",
    "        y_pred = []\n",
    "        for i in range(20):\n",
    "            y_pred_i = get_prediction(data, 'dlow', sample_num=cfg.nk, num_seeds=num_seeds, concat_hist=False)\n",
    "            y_pred_i = torch.tensor(y_pred_i).view(y_pred_i.shape[:-1] + (-1, 3))\n",
    "            y_pred.append(y_pred_i)\n",
    "        y_pred = torch.cat(y_pred, dim=1)\n",
    "        \n",
    "        # Add static positions\n",
    "        y_final = y_pred\n",
    "        y_pos = y_pos[..., kept_joints[1:], :] # Origin is filtered in get_prediction\n",
    "        \n",
    "        nll_list.append(compute_kde_nll(data[:, 25:, 1:], y_final))\n",
    "        \n",
    "        y_pos_pred_l.append(y_final)\n",
    "        y_pos_l.append(data[:, 25:, 1:])\n",
    "    \n",
    "y_pos_pred_11 = torch.cat(y_pos_pred_l, dim=0)\n",
    "y_pos_11 = torch.cat(y_pos_l, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "romance-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos_pred = torch.cat([y_pos_pred_9, y_pos_pred_11], dim=0)\n",
    "y_pos = torch.cat([y_pos_9, y_pos_11], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "controlling-version",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5168, 50, 100, 16, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pos_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "hispanic-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "apd = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    apd += compute_diversity(y_pos_pred[i, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "agreed-economics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.60039364358613"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apd / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "retired-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    ade += compute_ade(y_pos_pred[i, :50].flatten(start_dim=-2), y_pos[i].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "middle-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41767544380386273"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ade / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "valuable-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "fde = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    fde += compute_fde(y_pos_pred[i, :50].flatten(start_dim=-2), y_pos[i].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "going-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5141418853964967"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fde / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "moving-shooting",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "def get_multimodal_gt(dataset):\n",
    "    all_data = []\n",
    "    for x, y in dataset:\n",
    "        data = torch.cat([x, y], dim=0)\n",
    "        all_data.append(data)\n",
    "    all_data = torch.stack(all_data, axis=0)\n",
    "    all_data = skeleton(all_data.view(-1, 32, 4)).view(-1, all_data.shape[1], 32, 3) / 1000.\n",
    "    all_data = all_data[..., [0, 2, 1]] * torch.tensor([[[1., -1., 1.]]])\n",
    "    all_data = all_data[..., kept_joints, :]\n",
    "    all_data = all_data[..., 1:, :]\n",
    "    all_start_pose = all_data[:, t_his - 1, :].flatten(start_dim=-2)\n",
    "    pd = squareform(pdist(all_start_pose))\n",
    "    traj_gt_arr = []\n",
    "    for i in range(pd.shape[0]):\n",
    "        ind = np.nonzero(pd[i] < 0.5)\n",
    "        traj_gt_arr.append(all_data[ind][:, t_his:, :])\n",
    "    return traj_gt_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "deadly-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_set(skeleton, pos['S9']['Phoning'][100])\n",
    "m_gt_9 = get_multimodal_gt(dataset_eval_9)\n",
    "skeleton_set(skeleton, pos['S11']['Phoning 2'][100])\n",
    "m_gt_11 = get_multimodal_gt(dataset_eval_11)\n",
    "m_gt = m_gt_9 + m_gt_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "magnetic-librarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5168/5168 [06:12<00:00, 13.89it/s] \n"
     ]
    }
   ],
   "source": [
    "mmade = 0.\n",
    "for i in tqdm(range(y_pos.shape[0])):\n",
    "    mmade += compute_mmade(y_pos_pred[i, :50].flatten(start_dim=-2), None, m_gt[i].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "younger-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48554390516628054"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmade / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "flush-durham",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5168/5168 [05:51<00:00, 14.69it/s] \n"
     ]
    }
   ],
   "source": [
    "mmfde = 0.\n",
    "for i in tqdm(range(y_pos.shape[0])):\n",
    "    mmfde += compute_mmfde(y_pos_pred[i, :50].flatten(start_dim=-2), None, m_gt[i].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "liquid-emergency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5261071764924578"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmfde / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "social-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "apd = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    apd += compute_diversity(y_pos_pred[i, :50, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "classical-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.180428011832206"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apd / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "wireless-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "ade = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    ade += compute_ade(y_pos_pred[i, :50, :50].flatten(start_dim=-2), y_pos[i, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "genetic-shuttle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.305018526300119"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ade / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "invisible-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fde = 0.\n",
    "for i in range(y_pos.shape[0]):\n",
    "    fde += compute_fde(y_pos_pred[i, :50, :50].flatten(start_dim=-2), y_pos[i, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "economic-channel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4189206726572277"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fde / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adverse-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5168/5168 [03:07<00:00, 27.52it/s] \n"
     ]
    }
   ],
   "source": [
    "mmade = 0.\n",
    "for i in tqdm(range(y_pos.shape[0])):\n",
    "    mmade += compute_mmade(y_pos_pred[i, :50, :50].flatten(start_dim=-2), None, m_gt[i][:, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "reserved-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41667923668324486"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmade / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "contemporary-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5168/5168 [03:02<00:00, 28.24it/s] \n"
     ]
    }
   ],
   "source": [
    "mmfde = 0.\n",
    "for i in tqdm(range(y_pos.shape[0])):\n",
    "    mmfde += compute_mmfde(y_pos_pred[i, :50, :50].flatten(start_dim=-2), None, m_gt[i][:, :50].flatten(start_dim=-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "modular-administration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.453848048191137"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmfde / y_pos.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "unauthorized-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll = torch.cat(nll_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alike-interaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([115.6573,  53.8431, -12.9685, -51.4870, -69.4903, -78.1288, -82.5270,\n",
       "        -84.7968, -85.8376, -86.4732, -86.9339, -87.1482, -87.2519, -87.2515,\n",
       "        -87.2234, -87.0629, -86.8170, -86.5770, -86.1807, -85.7386, -85.3267,\n",
       "        -84.9387, -84.5291, -84.0931, -83.6289, -83.1264, -82.6000, -82.0796,\n",
       "        -81.4962, -80.8790, -80.2513, -79.6091, -79.0010, -78.3597, -77.7429,\n",
       "        -77.1220, -76.4933, -75.9142, -75.3304, -74.7518, -74.1841, -73.6319,\n",
       "        -73.0862, -72.5533, -72.0395, -71.5494, -71.0771, -70.6249, -70.1895,\n",
       "        -69.7316, -69.2791, -68.8391, -68.3947, -67.9507, -67.5247, -67.1117,\n",
       "        -66.6923, -66.2854, -65.8880, -65.5115, -65.1341, -64.7701, -64.4187,\n",
       "        -64.0621, -63.7194, -63.3797, -63.0506, -62.7341, -62.4353, -62.1468,\n",
       "        -61.8750, -61.6272, -61.3977, -61.1749, -60.9442, -60.7227, -60.5096,\n",
       "        -60.3074, -60.1050, -59.9169, -59.7381, -59.5634, -59.4109, -59.2708,\n",
       "        -59.1418, -59.0219, -58.9086, -58.8024, -58.6978, -58.6083, -58.5185,\n",
       "        -58.4486, -58.3861, -58.3287, -58.2748, -58.2284, -58.1905, -58.1610,\n",
       "        -58.1342, -58.0955])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll.clip(max=20).sum(-1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "known-burns",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9678e+03,  1.8360e+03,  7.4814e+02,  3.4263e+02,  1.6973e+02,\n",
       "         8.4026e+01,  3.4978e+01,  2.8629e+00, -1.8358e+01, -3.3132e+01,\n",
       "        -4.4400e+01, -5.2544e+01, -5.8882e+01, -6.3797e+01, -6.7706e+01,\n",
       "        -7.0686e+01, -7.3053e+01, -7.4968e+01, -7.6394e+01, -7.7393e+01,\n",
       "        -7.8195e+01, -7.8833e+01, -7.9099e+01, -7.9325e+01, -7.9435e+01,\n",
       "        -7.9377e+01, -7.9292e+01, -7.9068e+01, -7.8844e+01, -7.8516e+01,\n",
       "        -7.8109e+01, -7.7710e+01, -7.7343e+01, -7.6873e+01, -7.6407e+01,\n",
       "        -7.5954e+01, -7.5395e+01, -7.4909e+01, -7.4412e+01, -7.3916e+01,\n",
       "        -7.3413e+01, -7.2934e+01, -7.2450e+01, -7.1975e+01, -7.1517e+01,\n",
       "        -7.1058e+01, -7.0632e+01, -7.0210e+01, -6.9807e+01, -6.9374e+01,\n",
       "        -6.8953e+01, -6.8557e+01, -6.8147e+01, -6.7707e+01, -6.7294e+01,\n",
       "        -6.6893e+01, -6.6487e+01, -6.6094e+01, -6.5707e+01, -6.5341e+01,\n",
       "        -6.4977e+01, -6.4620e+01, -6.4275e+01, -6.3927e+01, -6.3591e+01,\n",
       "        -6.3258e+01, -6.2936e+01, -6.2623e+01, -6.2328e+01, -6.2046e+01,\n",
       "        -6.1764e+01, -6.1520e+01, -6.1295e+01, -6.1077e+01, -6.0851e+01,\n",
       "        -6.0637e+01, -6.0430e+01, -6.0240e+01, -6.0039e+01, -5.9855e+01,\n",
       "        -5.9681e+01, -5.9507e+01, -5.9358e+01, -5.9219e+01, -5.9092e+01,\n",
       "        -5.8973e+01, -5.8861e+01, -5.8755e+01, -5.8648e+01, -5.8560e+01,\n",
       "        -5.8472e+01, -5.8404e+01, -5.8341e+01, -5.8282e+01, -5.8227e+01,\n",
       "        -5.8183e+01, -5.8147e+01, -5.8118e+01, -5.8092e+01, -5.8056e+01])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll.sum(-1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-expert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "470611af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "t_his=25\n",
    "def get_multimodal_gt(dataset, threshold):\n",
    "    all_data = []\n",
    "    for x, y in dataset:\n",
    "        data = torch.cat([x, y], dim=0)\n",
    "        all_data.append(data)\n",
    "    all_data = torch.stack(all_data, axis=0)\n",
    "    all_data = skeleton(all_data.view(-1, 32, 4)).view(-1, all_data.shape[1], 32, 3) / 1000.\n",
    "    all_data = all_data[..., [0, 2, 1]] * torch.tensor([[[1., -1., 1.]]])\n",
    "    all_data = all_data[..., kept_joints, :]\n",
    "    all_data = all_data[..., 1:, :]\n",
    "    all_start_pose = all_data[:, t_his - 1, :].flatten(start_dim=-2)\n",
    "    pd = squareform(pdist(all_start_pose))\n",
    "    traj_gt_arr = []\n",
    "    for i in range(pd.shape[0]):\n",
    "        ind = np.nonzero(pd[i] < threshold)\n",
    "        traj_gt_arr.append(all_data[ind][:, t_his:, :])\n",
    "    return traj_gt_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "314f0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5168/5168 [00:04<00:00, 1169.19it/s]\n",
      "100%|██████████| 5168/5168 [00:05<00:00, 991.56it/s] \n",
      "100%|██████████| 5168/5168 [00:08<00:00, 582.30it/s]\n",
      "100%|██████████| 5168/5168 [00:07<00:00, 653.46it/s]\n",
      "100%|██████████| 5168/5168 [00:26<00:00, 194.52it/s]\n",
      "100%|██████████| 5168/5168 [00:26<00:00, 197.13it/s]\n",
      "100%|██████████| 5168/5168 [01:41<00:00, 50.88it/s] \n",
      "100%|██████████| 5168/5168 [01:32<00:00, 55.83it/s] \n",
      "100%|██████████| 5168/5168 [04:59<00:00, 17.23it/s] \n",
      "100%|██████████| 5168/5168 [04:46<00:00, 18.04it/s] \n"
     ]
    }
   ],
   "source": [
    "mmade_list = []\n",
    "mmfde_list = []\n",
    "with torch.no_grad():\n",
    "    for t in [0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "        skeleton_set(skeleton, pos['S9']['Phoning'][100])\n",
    "        m_gt_9 = get_multimodal_gt(dataset_eval_9, t)\n",
    "        skeleton_set(skeleton, pos['S11']['Phoning 2'][100])\n",
    "        m_gt_11 = get_multimodal_gt(dataset_eval_11, t)\n",
    "        m_gt = m_gt_9 + m_gt_11\n",
    "\n",
    "        mmade = 0.\n",
    "        for i in tqdm(range(y_pos.shape[0])):\n",
    "            mmade += compute_mmade(y_pos_pred[i, :50].flatten(start_dim=-2), None, m_gt[i].flatten(start_dim=-2))\n",
    "        mmade_list.append(mmade / y_pos.shape[0])\n",
    "\n",
    "        mmfde = 0.\n",
    "        for i in tqdm(range(y_pos.shape[0])):\n",
    "            mmfde += compute_mmfde(y_pos_pred[i, :50].flatten(start_dim=-2), None, m_gt[i].flatten(start_dim=-2))\n",
    "        mmfde_list.append(mmfde / y_pos.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43f6b639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41866363429582615, 0.42348777630507667, 0.43801822789278655, 0.459772969079968, 0.4856139307916626]\n",
      "[0.5127856655870983, 0.5126198851950351, 0.5158396173649159, 0.5196737145065062, 0.5255972387344107]\n"
     ]
    }
   ],
   "source": [
    "print(mmade_list)\n",
    "print(mmfde_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde21232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
